from __future__ import unicode_literals

from numpy.testing import assert_array_equal
from lstms_exploit_linguistic_attributes.utils import sort_batch_by_length
import torch

from .common.test_case import ReproducibleTestCase


class TestUtils(ReproducibleTestCase):
    def test_sort_tensor_by_length(self):
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        tensor = torch.rand([5, 7, 9])
        tensor[0, 3:, :] = 0
        tensor[1, 4:, :] = 0
        tensor[2, 1:, :] = 0
        tensor[3, 5:, :] = 0
        tensor.to(device)

        sequence_lengths = torch.LongTensor([3, 4, 1, 5, 7])
        sequence_lengths.to(device)
        (sorted_tensor, sorted_lengths,
         reverse_indices, _) = sort_batch_by_length(
             tensor, sequence_lengths)

        # Test sorted indices are padded correctly.
        assert_array_equal(
            sorted_tensor[1, 5:, :].to("cpu").detach().numpy(), 0.0)
        assert_array_equal(
            sorted_tensor[2, 4:, :].to("cpu").detach().numpy(), 0.0)
        assert_array_equal(
            sorted_tensor[3, 3:, :].to("cpu").detach().numpy(), 0.0)
        assert_array_equal(
            sorted_tensor[4, 1:, :].to("cpu").detach().numpy(), 0.0)

        assert sorted_lengths.detach().equal(torch.LongTensor([7, 5, 4, 3, 1]))

        # Test restoration indices correctly recover the original tensor.
        assert sorted_tensor.index_select(0, reverse_indices).data.equal(
            tensor.detach())
